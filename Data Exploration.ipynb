{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. When have there been spikes in UFO activity?\n",
    "2. How have UFO reports changed over time?\n",
    "3. Do more UFO sightings happen during day time or night time?\n",
    "4. What state has the most UFO reports per capita?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import ephem\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import patches as ptchs\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats as st\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful variables\n",
    "\n",
    "month_names = ['January', \n",
    "               'February', \n",
    "               'March', \n",
    "               'April',\n",
    "               'May', \n",
    "               'June', \n",
    "               'July', \n",
    "               'August', \n",
    "               'September', \n",
    "               'October', \n",
    "               'November', \n",
    "               'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/state_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fddb2385bff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maliens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Datasets/nuforc_events.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstate_populations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Datasets/state_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                       \u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abbreviation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                       \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'population'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\envs\\py39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datasets/state_data.csv'"
     ]
    }
   ],
   "source": [
    "# Data imports\n",
    "\n",
    "aliens = pd.read_csv('Datasets/nuforc_events.csv')\n",
    "state_populations = pd.read_csv('Datasets/state_data.csv')\\\n",
    "                      .set_index('abbreviation')\\\n",
    "                      [['state_name', 'population']]\n",
    "uscities = pd.read_csv('Datasets/uscities.csv')\\\n",
    "             [['city', 'state_id', 'lat', 'lng', 'timezone', 'population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_populations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uscities.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to date time objects\n",
    "aliens = aliens.dropna(subset = ['event_time'])\n",
    "aliens['event_time'] = pd.to_datetime(aliens['event_time'], format = '%Y-%m-%dT%H:%M:%SZ', errors = 'coerce')\n",
    "aliens = aliens.dropna(subset = ['event_time'])\n",
    "# There were about 20 invalid states in the set that needed to be removed.\n",
    "valid_state_names = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL',\n",
    "                     'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA',\n",
    "                     'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE',\n",
    "                     'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK',\n",
    "                     'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT',\n",
    "                     'VA', 'WA', 'WV', 'WI', 'WY', 'DC', 'PR', 'GU']\n",
    "# Remove all invalid states and convert all valid states to uppercase.\n",
    "aliens = aliens.dropna(subset = ['city', 'state'], how = 'any')\n",
    "aliens = aliens[aliens.state.isin(valid_state_names)].copy()\n",
    "aliens.state = list(map(lambda x : x.upper(), aliens.state))\n",
    "# Make every borough of New York count as a single city.\n",
    "def deborough(city):\n",
    "    \"\"\"Accepts a string. If that string contains 'new york city', returns\n",
    "    'NYC', otherwise returns the original string.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        city - string\n",
    "        \n",
    "    returns:\n",
    "        string which is either the city argument or 'NYC' depending on what the\n",
    "        city argument contains.\n",
    "    \"\"\"\n",
    "    if 'new york city' in city.lower():\n",
    "        return 'NYC'\n",
    "    else:\n",
    "        return city\n",
    "aliens.city = list(map(deborough, aliens.city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 Cleaning/Wrangling\n",
    "Do more UFO sightings happen during day time or night time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_observers(lat_list, \n",
    "                     lon_list, \n",
    "                     in_degrees = True):\n",
    "    \"\"\"Takes a list of latitudes and longitudes and yields a list of pyephem\n",
    "    observers containing those coordinates.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        lat_list - iterable of latitudes\n",
    "        lon_list - iterable of longitudes\n",
    "        \n",
    "    optional args:\n",
    "        in_degrees - boolean which if true denotes that the coordinates provided\n",
    "        are in degrees\n",
    "            defaults to True\n",
    "            \n",
    "    returns:\n",
    "        iterable of pyephem observers\n",
    "    \"\"\"\n",
    "    # Ephem takes lat/lon measures in radians, so degree coordinates need to be\n",
    "    # converted.\n",
    "    if in_degrees:\n",
    "        lat_list = np.radians(lat_list)\n",
    "        lon_list = np.radians(lon_list)\n",
    "    \n",
    "    for lat, lon in zip(lat_list, lon_list):\n",
    "        new_observer = ephem.Observer()\n",
    "        \n",
    "        new_observer.lat = lat\n",
    "        new_observer.lon = lon\n",
    "    \n",
    "        yield new_observer\n",
    "# Create ephem observers for each city from lat/long pairs.\n",
    "uscities['observer'] = list(create_observers(uscities['lat'], \n",
    "                                             uscities['lng']))\n",
    "# Create combination of city and state columns to be used as a key for merging\n",
    "# the uscities and aliens datasets.\n",
    "uscities['city_state'] = uscities['city'] + uscities['state_id']\n",
    "aliens['city_state'] = aliens['city'] + aliens['state']\n",
    "# Subset the cities data to make the final result less verbose.\n",
    "observers = uscities[['observer', 'city_state', 'timezone']].copy()\n",
    "\n",
    "aliens = aliens.merge(observers,\n",
    "                      left_on = 'city_state',\n",
    "                      right_on = 'city_state',\n",
    "                      how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens[['event_time', 'observer', 'timezone']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the highest population city for each state.\n",
    "uscities['state_max_pop'] = uscities[['state_id', 'population']]\\\n",
    "                                    .groupby('state_id')\\\n",
    "                                    ['population']\\\n",
    "                                    .transform(max)\n",
    "most_pop_cities = uscities[uscities.state_max_pop == uscities.population].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_pop_cities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the observer of the most populated city for the state provided.\n",
    "def substitute_default(column,\n",
    "                       key,\n",
    "                       data,\n",
    "                       default_column = None,\n",
    "                       default_key = None,\n",
    "                       defaults = pd.DataFrame()):\n",
    "    \"\"\"Replace nulls im column with defaults based on a key.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        column - name of column with nulls you would like to replace\n",
    "        key - key which matches null values with their replacements\n",
    "        data - pandas dataframe which contains the column and key specified\n",
    "        \n",
    "    optional args:\n",
    "        default_col - name of column with replacements for null values\n",
    "            if no vlaue is provided this equals \"column\"\n",
    "        default_key - key which matches replacements to null values\n",
    "            if no value is provided this equals \"key\"\n",
    "        defaults - pandas dataframe containing the replacements for null values\n",
    "        and the key need to match them\n",
    "            if no value is provided this equals \"data\"\n",
    "            \n",
    "    returns:\n",
    "        iterable equivalent to the original series but with nulls replaced by\n",
    "        specified defaults\n",
    "    \"\"\"\n",
    "    if default_column == None:\n",
    "        default_column = column\n",
    "    if default_key == None:\n",
    "        default_key = key\n",
    "    if defaults.shape[0] == 0:\n",
    "        defaults = data\n",
    "    for current_key, value in zip(data[key], data[column]):\n",
    "        if pd.isnull(value):\n",
    "            # Get the row from defaults where the value of the key column\n",
    "            # corresponds to the value of the key column for the current row.\n",
    "            query = '{} == \"{}\"'.format(default_key, current_key)\n",
    "            default = defaults.query(query)\n",
    "            # Yield the default that coresponds to the value of the key for the\n",
    "            # current row.\n",
    "            yield default.iloc[0][default_column]\n",
    "        else:\n",
    "            yield value\n",
    "# For every sighting that still doesn't have an observer, substitute that null\n",
    "# value with the observer for the most populated city within the state that the\n",
    "# sighting took place in.\n",
    "aliens['observer'] = list(substitute_default(column = 'observer',\n",
    "                                             key = 'state',\n",
    "                                             data = aliens,\n",
    "                                             default_key = 'state_id',\n",
    "                                             defaults = most_pop_cities))\n",
    "aliens['timezone'] = list(substitute_default(column = 'timezone',\n",
    "                                             key = 'state',\n",
    "                                             data = aliens,\n",
    "                                             default_key = 'state_id',\n",
    "                                             defaults = most_pop_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens[['event_time', 'observer', 'timezone']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps are submitted in the local time of whatever location they happen in\n",
    "# while ephem takes timestamps only in UTC.\n",
    "def convert_to_utc(timestamps, timezones):\n",
    "    \"\"\"Converts timestamps to UTC time using corresponding timezones as a\n",
    "    reference.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        timestamps - iterable of datetime objects\n",
    "        timezones - iterable of timezone names which correspond to the timezone\n",
    "        the timestamp was originally made in\n",
    "        \n",
    "    returns:\n",
    "        iterable of the orginal timestamps utc equivalents\"\"\"\n",
    "    for ts, tz in zip(timestamps, timezones):\n",
    "        ts = ts.replace(tzinfo = ZoneInfo(tz))\n",
    "        ts = ts.astimezone('UTC')\n",
    "        yield ts\n",
    "aliens['event_time_utc'] = list(convert_to_utc(aliens.event_time, \n",
    "                                               aliens.timezone))\n",
    "# Change the timestamp in each observer to the time of its sighting.\n",
    "def alter_time(timestamp, observer):\n",
    "    \"\"\"Changes the timestamp in the observer to the timestamp provided.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        timestamp - timestamp to which the date property of the observer should\n",
    "        be changed\n",
    "        observer - observer which should have its timestamp changed\n",
    "        \n",
    "    returns:\n",
    "        observer with timestamp assigned to date property\"\"\"\n",
    "    # Reformat the timestamp to be compatible with the observer.\n",
    "    timestamp = str(timestamp)\n",
    "    timestamp = re.sub('-', '/', timestamp)\n",
    "    timestamp = ephem.Date(timestamp)\n",
    "    # Had to make a new observer to get around a bug where only some of the\n",
    "    # observers wouldn't accept the new timestamp no matter what.\n",
    "    new_obs = ephem.Observer()\n",
    "    \n",
    "    new_obs.lat = observer.lat\n",
    "    new_obs.lon = observer.lon\n",
    "    new_obs.date = timestamp\n",
    "    \n",
    "    return new_obs\n",
    "# Alter the time of each observer to the time of their respective sightings.\n",
    "aliens.observer = list(map(alter_time, aliens.event_time_utc, aliens.observer))\n",
    "### Determine day/night for each sighting.\n",
    "def day_or_night(observer):\n",
    "    \"\"\"Determines whether the sun was up or down using the provided observer.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        observer - a pyephem observer object\n",
    "        \n",
    "    returns:\n",
    "        \"day\" or \"night\" depending on the altitude of the sun according to the\n",
    "        observer\n",
    "    \"\"\"\n",
    "    alt = str(ephem.Sun(observer).alt)\n",
    "    if alt[0] != '-':\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "# Add a column that denotes whether the sun was up or down during the sighting.\n",
    "aliens['day_night'] = list(map(day_or_night, aliens['observer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens[['event_time', 'event_time_utc', 'observer', 'timezone']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crate a column that counts the reports for each date.\n",
    "aliens['reports_this_date'] = aliens[['event_date', 'summary']]\\\n",
    "                                    .groupby('event_date')\\\n",
    "                                    .transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens[['event_date', 'reports_this_date']].head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 Cleaning/Wrangling\n",
    "What state has the most UFO reports per capita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before: 1,234,567 string\n",
    "# After:  1234567   int\n",
    "state_populations.population = list(map(lambda x : int(re.sub(',', '', x)),\n",
    "                                        state_populations.population))\n",
    "# Get the amount of reports from each state.\n",
    "state_reports = aliens[['state', 'summary']]\\\n",
    "                       .rename(columns = {'summary':'reports'})\\\n",
    "                       .groupby('state')\\\n",
    "                       .count()\n",
    "# Join the population data to the report data.\n",
    "states = state_reports.join(state_populations)\n",
    "# Find the most commonly reporting city per state.\n",
    "most_common_cities_per_state = aliens[['state', 'city']]\\\n",
    "                               .groupby('state')\\\n",
    "                               .agg(pd.Series.mode)\n",
    "# Calculate the reports per capita for every state.\n",
    "states['reports_per_capita'] = states.reports/states.population\n",
    "states = states.sort_values('reports_per_capita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.\n",
    "When have there been spikes in UFO activity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence Day Spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "july_means = aliens.query('year >= 2000 & month == 7')\\\n",
    "                   [['day', 'reports_this_date']]\\\n",
    "                   .groupby('day')\\\n",
    "                   .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure()\n",
    "ax = fig_1.add_axes([0.075, 0.075, 0.85, 0.85])\n",
    "\n",
    "ax.plot(july_means.index,\n",
    "        july_means.reports_this_date,\n",
    "        ls = ':',\n",
    "        color = (0.9, 0.4, 0.4),\n",
    "        marker = 'o')\n",
    "\n",
    "# Ticks\n",
    "ax.set_xticks(np.arange(1, 32))\n",
    "ax.set_xticklabels(np.arange(1, 32))\n",
    "ax.set_yticks(np.arange(0, 201, 20))\n",
    "ax.tick_params(rotation = 30, \n",
    "               axis = 'x',\n",
    "               labelsize = 8)\n",
    "\n",
    "# Labelling\n",
    "ax.set_title('Average UFO Reports Per Day In July');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rocket Launch Spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "november_2015_counts = aliens.query('year == 2015 & month == 11')\\\n",
    "                             .groupby('day')\\\n",
    "                             .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2 = plt.figure()\n",
    "ax = fig_2.add_axes([0.075, 0.075, 0.85, 0.85])\n",
    "\n",
    "ax.plot(november_2015_counts.index,\n",
    "        november_2015_counts.summary,\n",
    "        ls = ':',\n",
    "        color = (0.9, 0.4, 0.4),\n",
    "        marker = 'o')\n",
    "\n",
    "# Ticks\n",
    "ax.set_xticks(np.arange(1, 31))\n",
    "ax.set_xticklabels(np.arange(1, 31))\n",
    "ax.set_yticks(np.arange(0, 321, 40))\n",
    "ax.tick_params(rotation = 30, \n",
    "               axis = 'x',\n",
    "               labelsize = 8)\n",
    "\n",
    "# Labelling\n",
    "ax.set_title('UFO Reports in November 2015');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens.query('event_date == \"2015-11-07\"').event_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.\n",
    "How have UFO reports changed over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UFO Reports Per Year Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3 = plt.figure()\n",
    "ax = fig_3.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "ax.hist(aliens.year, \n",
    "        bins = np.arange(1956, 2018, 1),\n",
    "        color = (0.9, 0.4, 0.4),\n",
    "        align = 'left',\n",
    "        edgecolor = 'black',\n",
    "        zorder = 5)\n",
    "\n",
    "# Scaling\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(1955.5, 2016.5)\n",
    "\n",
    "#Ticks\n",
    "ax.set_xticks(np.arange(1956, 2017, 5))\n",
    "ax.set_yticks([100, 300, 1000, 3000, 10000])\n",
    "ax.set_yticklabels([100, 300, 1000, 3000, 10000])\n",
    "\n",
    "# Labelling\n",
    "ax.grid(zorder = 0)\n",
    "ax.set_title('UFO Reports Per Year From 1956 to 2016');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UFO Reports Per Month Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "aliens_no_4th = aliens.query('(day != 4 | month != 7)')\\\n",
    "                      .copy()\n",
    "# This will give each entry a column containing the total amount of reports\n",
    "# for that entry's year.\n",
    "aliens_no_4th['reports_this_year'] = aliens_no_4th[['year', 'summary']]\\\n",
    "                                                  .groupby('year')\\\n",
    "                                                  .transform('count')\n",
    "# This will give each entry a column containing the total amount of reports\n",
    "# for that entry's month.\n",
    "aliens_no_4th['reports_this_month'] = aliens_no_4th[['year', 'month', 'summary']]\\\n",
    "                                                   .groupby(['year', 'month'])\\\n",
    "                                                   .transform('count')\n",
    "\n",
    "aliens_no_4th['month_year_ratio'] = aliens_no_4th.reports_this_month/aliens_no_4th.reports_this_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matplotlib func animation takes 2 things: a function which returns a list\n",
    "# of artists, and a list of frames each of which are used as an arugment for the\n",
    "# function. I set this up so that the function would accept a dictionary.\n",
    "\n",
    "# The only consistent property within the dicts is the phase property, which is\n",
    "# used to determine which action the function should take. Everything else is\n",
    "# specific to whatever phase the frame is a part of.\n",
    "\n",
    "frames = []\n",
    "\n",
    "# These are some properties which allow for tweaking of the fade times.\n",
    "indv_fade_frames = 60\n",
    "minmax_fade_frames = 30\n",
    "\n",
    "# Buffer adds empty frames in whatever quantity is specified. This allows for\n",
    "# delays between state changes so as to better pace the animation.\n",
    "def buffer(count):\n",
    "    \"\"\"Adds buffer frames to the frames list.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        count - integer denoting the amount of buffer frames to add to the frame\n",
    "        list.\n",
    "        \n",
    "    returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for i in np.arange(count):\n",
    "        frame = {}\n",
    "        frame['phase'] = -1\n",
    "        frames.append(frame)\n",
    "\n",
    "# Make a frame for each year's month_year ratio line.\n",
    "for year in np.arange(2000, 2017, 1):\n",
    "    # Get the most common month/year ratio for each month in the current year.\n",
    "    ratios_by_month = aliens_no_4th.query('year == {}'.format(year))\\\n",
    "                                    [['month', 'month_year_ratio']]\\\n",
    "                                    .groupby('month')\\\n",
    "                                    .agg(pd.Series.mode)\n",
    "\n",
    "    frame = {}\n",
    "    frame['phase'] = 1\n",
    "    # This is used for the title changes.\n",
    "    frame['year'] = year\n",
    "    frame['positions'] = ratios_by_month\n",
    "    frames.append(frame)\n",
    "    # Add empty frames between this frame and the next.\n",
    "    buffer(5)\n",
    "    \n",
    "# Add one phase 2 frame to plot the initially invisible minimun and maximum\n",
    "# lines.\n",
    "frame = {}\n",
    "frame['phase'] = 2\n",
    "frames.append(frame)\n",
    "\n",
    "# Add frames to instruct the fade out of the individual ratio lines.\n",
    "for i in np.arange(indv_fade_frames):\n",
    "    frame = {}\n",
    "    frame['phase'] = 3\n",
    "    # The \"stage\" refers to how far into the fade the function is. The \"stages\"\n",
    "    # is there as context for the \"stage\". Using these, the function determines\n",
    "    # where inbetween the start and end colors the lines should be.\n",
    "    frame['stage'] = i\n",
    "    frame['stages'] = indv_fade_frames\n",
    "    frames.append(frame)\n",
    "\n",
    "# Add frames to instruct the fade in of the minimum and maximum ratio lines.\n",
    "for i in np.arange(minmax_fade_frames):\n",
    "    frame = {}\n",
    "    frame['phase'] = 4\n",
    "    # The \"stage\" refers to how far into the fade the function is. The \"stages\"\n",
    "    # is there as context for the \"stage\". Using these, the function determines\n",
    "    # where inbetween the start and end colors the lines should be.\n",
    "    frame['stage'] = i\n",
    "    frame['stages'] = minmax_fade_frames\n",
    "    frames.append(frame)\n",
    "    \n",
    "# Add empty frames at the end so that the animation doesn't immediately restart.\n",
    "buffer(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "ratio_group = aliens_no_4th.query('year >= 2000 & year <= 2016')\\\n",
    "              [['month', 'month_year_ratio']]\\\n",
    "              .groupby('month')\\\n",
    "              .month_year_ratio\\\n",
    "              .agg([pd.Series.min, pd.Series.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3 = plt.figure()\n",
    "ax = fig_3.add_axes([0.125, 0.125, 0.75, 0.75])\n",
    "\n",
    "# Scaling\n",
    "ax.set_ylim(0, 0.2)\n",
    "\n",
    "# Ticks\n",
    "ax.set_yticks(np.arange(0, 0.21, 0.1))\n",
    "ax.set_yticklabels(['0%', '10%', '20%'])\n",
    "ax.set_xticks(np.arange(0,12))\n",
    "ax.set_xticklabels(month_names)\n",
    "ax.tick_params(rotation = 30, axis = 'x')\n",
    "\n",
    "# Labelling\n",
    "ax.set_ylabel('Percentage of year\\'s UFO reports')\n",
    "ax.grid()\n",
    "\n",
    "# These are all persistent variables for the plot_reports_by_month function \n",
    "# below.\n",
    "indv_lines = []\n",
    "minmax_lines = []\n",
    "\n",
    "color_1 = (0.9, 0.4, 0.4, 1)\n",
    "color_2 = (0.8, 0.8, 0.8, 1)\n",
    "color_3 = (0.9, 0.4, 0.4, 0)\n",
    "\n",
    "def plot_reports_by_month(frame):\n",
    "    \"\"\"Returns a list of artists which make up a frame of animation. This frame\n",
    "    is generated according to the properties of the frame object.\n",
    "    \n",
    "    ----------------------------------------------------------------------------\n",
    "    \n",
    "    args:\n",
    "        frame - dictionary containing relevant properties including the type of\n",
    "        frame you want to generate and the data needed for that frame\n",
    "        \n",
    "    returns:\n",
    "        iterable of matplotlib artists\n",
    "    \"\"\"\n",
    "    # Phase 1 plots the individual month/year ratios for each year from 2000\n",
    "    # to 2016. These lines accumulate on top of each other instead of replacing\n",
    "    # or modifying the previous line.\n",
    "    if frame.get('phase') == 1:\n",
    "        # Update the title to reflect the year range being presented.\n",
    "        ax.set_title('2000 - {}'.format(frame.get('year')))\n",
    "        # Plot the month/year ratios for the current year and append that line\n",
    "        # to the indv_lines list so that it can be recolored later.\n",
    "        indv_lines.append(ax.plot(np.arange(0, 12), \n",
    "                          frame.get('positions'), \n",
    "                          color = color_1, \n",
    "                          marker = '.'))\n",
    "        return indv_lines\n",
    "    # Phase 2 plots two lines, one representing the minimum month/year ratio\n",
    "    # for each month across every year, and the other representing the maximum.\n",
    "    if frame.get('phase') == 2:\n",
    "        # Plot the minimum and maximum ratio lines, and append them to the\n",
    "        # minmax_lines list so they can be recolored later. They start out with\n",
    "        # an alpha of 0 so they can be faded in in phase 4.\n",
    "        minmax_lines.append(ax.plot(np.arange(12),\n",
    "                            ratio_group['min'],\n",
    "                            color = color_3,\n",
    "                            marker = 'o'))\n",
    "        minmax_lines.append(ax.plot(np.arange(12), \n",
    "                            ratio_group['max'], \n",
    "                            color = color_3,\n",
    "                            marker = 'o'))\n",
    "        return minmax_lines\n",
    "    # Phase 3 fades the ratio lines for each year from pastel red to light grey.\n",
    "    if frame.get('phase') == 3:\n",
    "        # Linearly interpolate between the start and end color using the stage\n",
    "        # property of this frame as a guide.\n",
    "        indv_lines_stage = np.linspace(color_1, \n",
    "                                       color_2, \n",
    "                                       frame.get('stages'))[frame.get('stage')]\n",
    "        # Update each line in the individual lines list with the new color.\n",
    "        for line, in indv_lines:\n",
    "            line.set_color(indv_lines_stage)\n",
    "    # Phase 4 fades the minimum and maximum ratio lines in over the top of the\n",
    "    # individual lines.\n",
    "    if frame.get('phase') == 4:\n",
    "        # Interpolate between the start and end color using the stage property\n",
    "        # of this frame as a guide.\n",
    "        minmax_lines_stage = np.linspace(color_3, \n",
    "                                         color_1, \n",
    "                                         frame.get('stages'))[frame.get('stage')]\n",
    "        # Update both lines in the minmax_lines list with the cne wcolor.\n",
    "        for line, in minmax_lines:\n",
    "            line.set_color(minmax_lines_stage)\n",
    "\n",
    "ani = FuncAnimation(fig = fig_3,\n",
    "                    func = plot_reports_by_month,\n",
    "                    frames = frames,\n",
    "                    blit = True,\n",
    "                    interval = 1000/30)\n",
    "# The ipympl backend makes this notbook get very slow when this plot is rendered\n",
    "# as interactive, so it needs to be closed.\n",
    "plt.close()\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.\n",
    "Do more UFO sightings happen during day time or night time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day/Night Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "day_night_counts = aliens[['day_night', 'summary']].groupby('day_night').count()\n",
    "\n",
    "day_ratio = day_night_counts.loc['day']['summary']/aliens.shape[0]\n",
    "night_ratio = day_night_counts.loc['night']['summary']/aliens.shape[0]\n",
    "\n",
    "day_ratio = np.round(day_ratio, 2)\n",
    "night_ratio = np.round(night_ratio, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_6 = plt.figure()\n",
    "ax = fig_6.add_axes([0, 0, 1, 1])\n",
    "#\n",
    "# Useful constants.\n",
    "#\n",
    "center = (0, 0)\n",
    "radius = 1.75\n",
    "xlim = 2.666666\n",
    "ylim = 2\n",
    "dn_palette = {\n",
    "    'moon':(0.8, 0.8, 0.8),\n",
    "    'mooncrater':(0.6, 0.6, 0.6),\n",
    "    'sun':(0.95, 0.76, 0.29),\n",
    "    'night':(0.31, 0, 0.55),\n",
    "    'skyblue':(0.75, 0.75, 1),\n",
    "    'sunray':(0.85 , 0.755, 0.645)\n",
    "}\n",
    "\n",
    "slices = ax.pie([day_ratio, night_ratio],\n",
    "              startangle = 90,\n",
    "              colors = [dn_palette.get('sun'), dn_palette.get('moon')],\n",
    "              counterclock = False,\n",
    "              center = center,\n",
    "              radius = radius,\n",
    "              normalize = False)\n",
    "# Sun Z-order\n",
    "slices[0][0] = slices[0][0].set_zorder(-2)\n",
    "# Moon Z-order\n",
    "slices[0][1] = slices[0][1].set_zorder(-4)\n",
    "# Limits\n",
    "ax.set_xlim(-xlim, xlim)\n",
    "ax.set_ylim(-ylim, ylim)\n",
    "ax.set_aspect('equal')\n",
    "#\n",
    "# Pie Border\n",
    "#\n",
    "border = ptchs.Circle(center, \n",
    "                      radius, \n",
    "                      fill=False, \n",
    "                      edgecolor=\"k\", \n",
    "                      linewidth=1.5, \n",
    "                      antialiased = True,\n",
    "                      zorder = -1)\n",
    "ax.add_patch(border)\n",
    "#\n",
    "# Moon\n",
    "#\n",
    "class Crater:\n",
    "    \"\"\"This class generates a circle patch which can be added to a plot. These\n",
    "    patches are meant to represent craters on the moon.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 center, \n",
    "                 radius, \n",
    "                 color = dn_palette.get('mooncrater')):\n",
    "        \"\"\"args:\n",
    "            center - tuple containing the xy coords for the center of the crater\n",
    "            radius - float which sets the radius of the crater\n",
    "        optional args:\n",
    "            color - either name of color or iterable containing rgb(a) values\n",
    "                defaults to mooncrater color in dn_palette\n",
    "        \"\"\"\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.color = color\n",
    "        \n",
    "    def generate(self):\n",
    "        \"\"\" Use this to get the circle patch after instatiating the crater.\n",
    "        \n",
    "        ------------------------------------------------------------------------\n",
    "    \n",
    "        returns:\n",
    "            a circle patch made using the provided properties\n",
    "        \"\"\"\n",
    "        return ptchs.Circle(xy = crater.center,\n",
    "                            radius = crater.radius,\n",
    "                            color = crater.color,\n",
    "                            zorder = -3)\n",
    "# Crater positions and sizes.\n",
    "craters = [\n",
    "    Crater((-1.5, 0), 0.2),\n",
    "    Crater((-1, 0.75), 0.45),\n",
    "    Crater((-0.9, -0.8), 0.5),\n",
    "    Crater((-0.5, 1.2), 0.3),\n",
    "    Crater((-0.3, -0.3), 0.15),\n",
    "    Crater((-0.7, 0.1), 0.24),\n",
    "    Crater((-0.3, 0.5), 0.2),\n",
    "    Crater((0.3, 0.5), 0.4),\n",
    "    Crater((0, -0.4), 0.3),\n",
    "    Crater((0.7, -1.2), 0.2),\n",
    "    Crater((0.3, 0.5), 0.4),\n",
    "    Crater((0.5, -0.8), 0.3),\n",
    "    Crater((0.7, 0.3), 0.2),\n",
    "    Crater((1.2, -0.35), 0.4),\n",
    "    Crater((0, -1.2), 0.4),\n",
    "    Crater((0.075, 1.4), 0.25)\n",
    "]\n",
    "# Add each crater to the axes object.\n",
    "for crater in craters:\n",
    "    circle = crater.generate()\n",
    "    ax.add_patch(circle)\n",
    "#\n",
    "# Night/Day Background\n",
    "#\n",
    "# Set the figure color\n",
    "fig_6.patch.set_facecolor('k')\n",
    "# Make a polygon with complimentary shape to the pie chart for the sunny sky.\n",
    "verts = [(0, 0),\n",
    "         (0, ylim),\n",
    "         (xlim, ylim),\n",
    "         (xlim, 0.7)]\n",
    "sky = ptchs.Polygon(xy = verts,\n",
    "                          closed = True,\n",
    "                          color = dn_palette.get('skyblue'),\n",
    "                          zorder = -7)\n",
    "ax.add_patch(sky)\n",
    "#\n",
    "# Stars\n",
    "#\n",
    "class Star:\n",
    "    \"\"\"This class generates a polygon patch resembling a star. The star has four\n",
    "    points, one in each cardinal direction. The vertices at the points are\n",
    "    referred to by this class as \"major vertices\". Of course there are \"minor\n",
    "    vertices\" as well, which represent the corners in between these vertices.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 center = (0, 0),\n",
    "                 major_length = 0.03,\n",
    "                 minor_length = 0.01,\n",
    "                 major_noise = 0.003,\n",
    "                 minor_noise = 0.001):\n",
    "        \"\"\"optional args:\n",
    "            center - tuple containing the xy coords for the center of the star\n",
    "                defaults to (0, 0)\n",
    "            major_length - major points' distance from the center\n",
    "                defaults to 0.03\n",
    "            minor_length - minor points' distance from the center\n",
    "                defaults to 0.01\n",
    "            major_noise - max amount of randomly generate length to add to the\n",
    "            major length\n",
    "                defaults to 0.003\n",
    "            major_noise - max amount of randomly generate length to add to the\n",
    "            minor length\n",
    "                defaults to 0.001\n",
    "        \n",
    "        \"\"\"\n",
    "        self.x = center[0]\n",
    "        self.y = center[1]\n",
    "        # Add noise to the major and minor points.\n",
    "        self.major_length = major_length + np.random.random() * major_noise\n",
    "        self.minor_length = minor_length + np.random.random() * minor_noise\n",
    "        # The base color for each star is (0.9, 0.9, 0.9).\n",
    "        # Then a distinct random value between 0 and 0.1 is added to each value.\n",
    "        self.color = np.full(3, 0.9) + np.random.random(3) * 0.1\n",
    "        \n",
    "    def generate_star(self):\n",
    "        \"\"\"Creates a polygon patch resembling a star, the properties of which\n",
    "        are set when initializing the object.\n",
    "        \n",
    "        ------------------------------------------------------------------------\n",
    "    \n",
    "        returns:\n",
    "            polygon patch that resembles a star\n",
    "        \"\"\"\n",
    "        # Multiply the length of the major and minor points by the provided\n",
    "        # lengths.\n",
    "        majors = np.array([\n",
    "            (0, 1),\n",
    "            (1, 0),\n",
    "            (0, -1),\n",
    "            (-1, 0)\n",
    "        ]) * self.major_length\n",
    "        minors = np.array([\n",
    "            (1, 1),\n",
    "            (1, -1),\n",
    "            (-1, -1),\n",
    "            (-1, 1)\n",
    "        ]) * self.minor_length\n",
    "        # Interlace the major and minor points into a single list.\n",
    "        verts = np.array([0, 0])\n",
    "        for major, minor in zip(majors, minors):\n",
    "            verts = np.vstack([verts, [major[0], major[1]]])\n",
    "            verts = np.vstack([verts, [minor[0], minor[1]]])\n",
    "        verts = verts[1:]\n",
    "        # Center the points around the provided center coordinates.\n",
    "        verts[:, 0] += self.x\n",
    "        verts[:, 1] += self.y\n",
    "        # Return a polygon made using the vertex list.\n",
    "        star = ptchs.Polygon(xy = verts,\n",
    "                             color = self.color,\n",
    "                             zorder = -8)\n",
    "        return star\n",
    "    \n",
    "    def generate_halo(self):\n",
    "        \"\"\"The halo is an optional extra patch, the radius of which exceeds the\n",
    "        star's major length. The color of the halo is 15% as bright as the\n",
    "        star's color, in order to give the appearance of translucency.\n",
    "        \n",
    "        ------------------------------------------------------------------------\n",
    "    \n",
    "        returns:\n",
    "            circle patch which will be rendered behind the star\n",
    "        \"\"\"\n",
    "        return ptchs.Circle((self.x, self.y),\n",
    "                            color = self.color * 0.15,\n",
    "                            radius = self.major_length * 2,\n",
    "                            zorder = -9)\n",
    "# Generate 100 stars with coordinates in the left half of the axis. The blue sky\n",
    "# polygon is above the star layer so the stars won't overlap despite the odd \n",
    "# night sky boundary.\n",
    "stars = []\n",
    "for i in np.arange(200):\n",
    "    stars.append(Star((np.random.random() * -(xlim * 2) + xlim, \n",
    "                       np.random.random() * -(ylim * 2) + ylim)))\n",
    "# Add stars to the axes obejct.\n",
    "for star in stars:\n",
    "    ax.add_patch(star.generate_halo())\n",
    "    ax.add_patch(star.generate_star())\n",
    "#\n",
    "# Sunrays\n",
    "#\n",
    "# Each ray is a triangle with a point at 0, so each of these tuples defines the \n",
    "# two other points.\n",
    "rays = [\n",
    "#   [(  x  ,  y  )  (  x  ,  y  )],\n",
    "    [(    0,    4), ( 0.78, 3.92)],\n",
    "    [( 1.53, 3.69), ( 2.22, 3.32)],\n",
    "    [( 2.83, 2.83), ( 3.32, 2.22)],\n",
    "    [( 3.70, 1.53), ( xlim, 0.7)]\n",
    "]\n",
    "# Add a triangle to the axes object with provided points for each tuple in the \n",
    "# rays list.\n",
    "for ray in rays:\n",
    "    verts = [(0, 0)]\n",
    "    verts.extend(ray)\n",
    "    ax.add_patch(ptchs.Polygon(verts,\n",
    "                               color = dn_palette.get('sunray'),\n",
    "                               zorder = -5))\n",
    "#\n",
    "#\n",
    "# - Z-Order Cheatsheet -\n",
    "#   0 ~ Text\n",
    "#  -1 ~ Border\n",
    "#  -2 ~ Sun\n",
    "#  -3 ~ Craters\n",
    "#  -4 ~ Moon\n",
    "#  -5 ~ Sun Rays\n",
    "#  -6 ~ Clouds (Not Used)\n",
    "#  -7 ~ Blue Sky\n",
    "#  -8 ~ Stars\n",
    "#  -9 ~ Star Halos\n",
    "# -10 ~ Night Sky/Figure\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative UFO Reports Per Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_7 = plt.figure()\n",
    "ax = fig_7.add_axes([0.1, 0.1, .8, .8])\n",
    "\n",
    "# Head (0 - 7) gradient colors.\n",
    "head = list(np.linspace(dn_palette.get('night'),\n",
    "                        dn_palette.get('sun'),\n",
    "                        num = 8))\n",
    "# Body (8 - 15) solid color.\n",
    "body = np.full((7, 3), \n",
    "               dn_palette.get('sun'))\n",
    "# Tail (16 - 24) gradient colors.\n",
    "tail = list(np.linspace(dn_palette.get('sun'),\n",
    "                        dn_palette.get('night'),\n",
    "                        num = 9))\n",
    "# Combine colors sequences into single list.\n",
    "colors = []\n",
    "colors.extend(head)\n",
    "colors.extend(body)\n",
    "colors.extend(tail)\n",
    "\n",
    "bars = ax.hist(aliens.hour, bins = np.arange(25))\n",
    "\n",
    "# Set the color of each bar according to the sequence above.\n",
    "for i, bar in enumerate(bars[2]):\n",
    "    bar.set_color(colors[i])\n",
    "# Ticks\n",
    "ax.set_xticks(np.arange(25))\n",
    "ax.set_xlim(0, 24)\n",
    "# Labelling\n",
    "ax.set_title('Cumulative Reports Per Hour');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.\n",
    "What state has the most UFO reports per capita?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UFO Reports Per Capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_5 = plt.figure()\n",
    "ax = fig_5.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "bars = ax.barh(states.index,\n",
    "               states.reports_per_capita,\n",
    "               height = 1,\n",
    "               edgecolor = 'black',\n",
    "               color = (0.9, 0.4, 0.4))\n",
    "\n",
    "# Scaling\n",
    "ax.set_ylim([-0.5, 51.5])\n",
    "\n",
    "# Ticks\n",
    "ax.tick_params(labelsize = 5, axis = 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "- UFO Reports: http://www.nuforc.org/ though I used this dataset generated from nuforc instead of getting it directly https://data.world/khturner/national-ufo-reporting-center-reports\n",
    "- Cities data: https://simplemaps.com/data/us-cities\n",
    "- Latest Sunrise and Earliest Sunset: https://abc7ny.com/winter-solstice-latest-sunrise-earliest-sunset-solar-time/8593291/#:~:text=However%2C%20the%20earliest%20sunset%20date,2021%20at%207%3A20%20a.m.\n",
    "- State Population Data (I cleaned it up myself in google sheets): https://www.census.gov/data/datasets/time-series/demo/popest/2010s-state-total.html\n",
    "- Various: https://www.wikipedia.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39]",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
